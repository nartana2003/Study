import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import make_blobs

# Generate sample data
X, y_true = make_blobs(n_samples=300, centers=4, cluster_std=0.60, random_state=0)

# Visualize the data
plt.scatter(X[:, 0], X[:, 1], s=50)
plt.show()

# K-means algorithm
def kmeans(X, k, max_iters=100, plot_steps=False):
    """
    K-Means clustering algorithm.

    Parameters:
    - X: Data points (ndarray of shape (n_samples, n_features))
    - k: Number of clusters
    - max_iters: Maximum number of iterations
    - plot_steps: Boolean, if True, plots each iteration

    Returns:
    - clusters: Cluster labels for each point
    - centroids: Final centroid positions
    """
    # Randomly initialize the centroids
    np.random.seed(42)
    centroids = X[np.random.choice(X.shape[0], k, replace=False)]

    for i in range(max_iters):
        # Assign each point to the nearest centroid
        distances = np.linalg.norm(X[:, np.newaxis] - centroids, axis=2)
        clusters = np.argmin(distances, axis=1)

        if plot_steps:
            plt.scatter(X[:, 0], X[:, 1], c=clusters, cmap='viridis', s=50)
            plt.scatter(centroids[:, 0], centroids[:, 1], c='red', s=200, alpha=0.5)
            plt.title(f"Iteration {i+1}")
            plt.show()

        # Calculate new centroids as the mean of the clusters
        new_centroids = np.array([X[clusters == j].mean(axis=0) for j in range(k)])

        # Check for convergence
        if np.all(centroids == new_centroids):
            break

        centroids = new_centroids

    return clusters, centroids

# Set number of clusters
k = 4

# Run K-means algorithm
clusters, centroids = kmeans(X, k, plot_steps=True)

# Plot the final result
plt.scatter(X[:, 0], X[:, 1], c=clusters, cmap='viridis', s=50)
plt.scatter(centroids[:, 0], centroids[:, 1], c='red', s=200, alpha=0.75)
plt.title("Final Clustering Result")
plt.show()
